{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# 예시 데이터\n",
    "head = [\n",
    "    \"경제 성장률 상승으로 주가 상승세\",\n",
    "    \"기업 이익 증가에 따른 투자자 신뢰 증가\",\n",
    "    \"실업률 상승으로 경제 불안정 우려\",\n",
    "    \"금리 인상으로 주식 시장에 악영향\",\n",
    "    \"수출 감소로 인한 경제 성장 둔화\",\n",
    "    \"신기술 개발로 기업 가치 상승 예상\"\n",
    "]\n",
    "type = [1, 1, 0, 0, 0, 1]  # 호재는 1, 악재는 0\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(head)\n",
    "y = type\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 훈련\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"정확도: {score:.2f}\")\n",
    "\n",
    "# 모델과 벡터라이저를 파일로 저장\n",
    "joblib.dump(model, 'news_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 벡터라이저를 파일로부터 불러오기\n",
    "model = joblib.load('news_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# 새로운 데이터에 대한 예측\n",
    "new_news = [\"금융 위기로 인한 경제 충격\", \"기술 혁신으로 새로운 시장 창출\"]\n",
    "new_news_vector = tfidf_vectorizer.transform(new_news)\n",
    "predictions = model.predict(new_news_vector)\n",
    "print(predictions)   # [0 1]과 같이 악재(0)와 호재(1)를 나타냄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oasispapa/Develop/Homework/TextAnalyzer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.999362051486969}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"gabrielyang/finance_news_classifier-KR_v7\")\n",
    "text = \"금리 인상으로 주식 시장에 악영향\"\n",
    "result = pipe(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gabrielyang/finance_news_classifier-KR_v7\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gabrielyang/finance_news_classifier-KR_v7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 호악재 분석 (고급 버전)\n",
    "def analyze_news(news):\n",
    "    # Load model directly\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gabrielyang/finance_news_classifier-KR_v7\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"gabrielyang/finance_news_classifier-KR_v7\")\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(news, return_tensors=\"pt\")\n",
    "    # Perform inference\n",
    "    outputs = model(**inputs)\n",
    "    # Get predicted class\n",
    "    predicted_class_idx = outputs.logits.argmax().item()\n",
    "    # Get predicted class name\n",
    "    predicted_class_name = model.config.id2label[predicted_class_idx]\n",
    "    return predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "text = \"금리 인상으로 주식 시장에 악영향\"\n",
    "result = analyze_news(text)\n",
    "print(result)  # 악재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import telegram\n",
    "import asyncio\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "\n",
    "# 연합뉴스 (오늘)\n",
    "def get_news_from_yonhap(): \n",
    "    # URL of the RSS feed\n",
    "    url = \"https://www.yonhapnewstv.co.kr/category/news/economy/feed/\"\n",
    "\n",
    "    # Fetch the RSS feed\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "\n",
    "    # Parse the XML\n",
    "    soup = BeautifulSoup(response.text, \"xml\")\n",
    "    # 뉴스 제목\n",
    "    titles = [item.find('title').text for item in soup.find_all('item')]\n",
    "    # 뉴스 내용\n",
    "    encoded_contents = [item.find('content:encoded').text for item in soup.find_all('item')]\n",
    "    # 링크\n",
    "    links = [item.find('link').text for item in soup.find_all('item')]\n",
    "    return titles, encoded_contents, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, news, links = get_news_from_yonhap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"gabrielyang/finance_news_classifier-KR_v7\")   \n",
    "\n",
    "# 한번에 분석하기 힘든 긴 텍스트 때문에 청크로 자른다. \n",
    "max_length = 512  # Assuming the model's max token length is 512\n",
    "text_chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "# 예측을 진행하고 결과를 청크별로 나눠 담는다\n",
    "results = []\n",
    "for chunk in text_chunks:\n",
    "    result = pipe(chunk)\n",
    "    result[0]['length'] = len(chunk)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'negative', 'score': 0.7202937602996826, 'length': 414}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weighted_results = {}\n",
    "for result in results:\n",
    "    for res in result:\n",
    "        label = res['label']\n",
    "        length = res['length']\n",
    "        if label in weighted_results:\n",
    "            weighted_results[label] += length\n",
    "        else:\n",
    "            weighted_results[label] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_label = max(weighted_results, key=weighted_results.get)\n",
    "most_common_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
